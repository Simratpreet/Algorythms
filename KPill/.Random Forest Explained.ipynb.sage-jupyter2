{"type":"cell","id":"051fa0","pos":18,"input":"## Make Predictions on Test Data","cell_type":"markdown"}
{"type":"cell","id":"0ccc89","pos":2,"input":"print('The shape of our features is:', features.shape)","output":{"0":{"name":"stdout","output_type":"stream","text":"The shape of our features is: (348, 9)\n"}},"cell_type":"code","exec_count":2,"metadata":{"hideCode":false,"hidePrompt":false}}
{"type":"cell","id":"14fc4f","pos":0,"input":"# Data Preparation","cell_type":"markdown"}
{"type":"cell","id":"181ad3","pos":4,"input":"One hot encoding takes this:\n\n| week |\n|------|\n| Mon  |\n| Tue  |\n| Wed  |\n| Thu  |\n| Fri  |\n\nand converts it into:\n\n| Mon | Tue | Wed | Thu | Fri |\n|-----|-----|-----|-----|-----|\n| 1   | 0   | 0   | 0   | 0   |\n| 0   | 1   | 0   | 0   | 0   |\n| 0   | 0   | 1   | 0   | 0   |\n| 0   | 0   | 0   | 1   | 0   |\n| 0   | 0   | 0   | 0   | 1   |","cell_type":"markdown"}
{"type":"cell","id":"1a5cfe","pos":27,"input":"![Small Decision Tree](small_tree.PNG)","cell_type":"markdown"}
{"type":"cell","id":"279da9","pos":28,"input":"### Annotated Version of Tree","cell_type":"markdown"}
{"type":"cell","id":"295df7","pos":21,"input":"## Visualizing a Single Decision Tree","cell_type":"markdown"}
{"type":"cell","id":"35b3a2","pos":19,"input":"# Use the forest's predict method on the test data\npredictions = rf.predict(test_features)\n\n# Calculate the absolute errors\nerrors = abs(predictions - test_labels)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Mean Absolute Error: 3.83 degrees.\n"}},"cell_type":"code","exec_count":11}
{"type":"cell","id":"3a92dc","pos":6,"input":"print('Shape of features after one-hot encoding:', features.shape)","output":{"0":{"name":"stdout","output_type":"stream","text":"Shape of features after one-hot encoding: (348, 15)\n"}},"cell_type":"code","exec_count":4}
{"type":"cell","id":"4b3dc8","pos":5,"input":"# One-hot encode categorical features\nfeatures = pd.get_dummies(features)\nfeatures.head(5)","output":{"0":{"data":{"text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>temp_2</th>\n      <th>temp_1</th>\n      <th>average</th>\n      <th>actual</th>\n      <th>friend</th>\n      <th>week_Fri</th>\n      <th>week_Mon</th>\n      <th>week_Sat</th>\n      <th>week_Sun</th>\n      <th>week_Thurs</th>\n      <th>week_Tues</th>\n      <th>week_Wed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>45</td>\n      <td>45</td>\n      <td>45.6</td>\n      <td>45</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>44</td>\n      <td>45</td>\n      <td>45.7</td>\n      <td>44</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>45</td>\n      <td>44</td>\n      <td>45.8</td>\n      <td>41</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>4</td>\n      <td>44</td>\n      <td>41</td>\n      <td>45.9</td>\n      <td>40</td>\n      <td>53</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>41</td>\n      <td>40</td>\n      <td>46.0</td>\n      <td>44</td>\n      <td>41</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"output_type":"execute_result","exec_count":3}},"cell_type":"code","exec_count":3,"metadata":{"hideCode":false,"hidePrompt":false}}
{"type":"cell","id":"506c0a","pos":15,"input":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Instantiate model \nrf = RandomForestRegressor(n_estimators= 1000, random_state=42)\n\n# Train the model on training data\nrf.fit(train_features, train_labels);","cell_type":"code","exec_count":9,"metadata":{"hideCode":false,"hidePrompt":false}}
{"type":"cell","id":"52a290","pos":12,"input":"## Establish Baseline","cell_type":"markdown"}
{"type":"cell","id":"52d8a2","pos":8,"input":"# Use numpy to convert to arrays\nimport numpy as np\n\n# Labels are the values we want to predict\nlabels = np.array(features['actual'])\n\n# Remove the labels from the features\n# axis 1 refers to the columns\nfeatures= features.drop('actual', axis = 1)\n\n# Saving feature names for later use\nfeature_list = list(features.columns)\n\n# Convert to numpy array\nfeatures = np.array(features)","cell_type":"code","exec_count":5}
{"type":"cell","id":"5d1799","pos":34,"input":"## Visualizations","cell_type":"markdown","collapsed":true}
{"type":"cell","id":"76179f","pos":24,"input":"print('The depth of this tree is:', tree.tree_.max_depth)","output":{"0":{"name":"stdout","output_type":"stream","text":"The depth of this tree is: 15\n"}},"cell_type":"code","exec_count":14}
{"type":"cell","id":"784667","pos":23,"input":"![Decision Tree](tree.png)","cell_type":"markdown"}
{"type":"cell","id":"857d13","pos":32,"input":"### Two Most Important Features","cell_type":"markdown"}
{"type":"cell","id":"8d28ef","pos":13,"input":"# The baseline predictions are the historical averages\nbaseline_preds = test_features[:, feature_list.index('average')]\n\n# Baseline errors, and display average baseline error\nbaseline_errors = abs(baseline_preds - test_labels)\nprint('Average baseline error: ', round(np.mean(baseline_errors), 2), 'degrees.')","output":{"0":{"name":"stdout","output_type":"stream","text":"Average baseline error:  5.06 degrees.\n"}},"cell_type":"code","exec_count":8}
{"type":"cell","id":"9593a9","pos":31,"input":"# Get numerical feature importances\nimportances = list(rf.feature_importances_)\n\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","output":{"0":{"name":"stdout","output_type":"stream","text":"Variable: temp_1               Importance: 0.7\nVariable: average              Importance: 0.19\nVariable: day                  Importance: 0.03\nVariable: temp_2               Importance: 0.02\nVariable: friend               Importance: 0.02\nVariable: month                Importance: 0.01\nVariable: year                 Importance: 0.0\nVariable: week_Fri             Importance: 0.0\nVariable: week_Mon             Importance: 0.0\nVariable: week_Sat             Importance: 0.0\nVariable: week_Sun             Importance: 0.0\nVariable: week_Thurs           Importance: 0.0\nVariable: week_Tues            Importance: 0.0\nVariable: week_Wed             Importance: 0.0\n"}},"cell_type":"code","exec_count":16}
{"type":"cell","id":"9a7949","pos":20,"input":"# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / test_labels)\n\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","output":{"0":{"name":"stdout","output_type":"stream","text":"Accuracy: 93.99 %.\n"}},"cell_type":"code","exec_count":12}
{"type":"cell","id":"a07023","pos":39,"input":"","cell_type":"code","exec_count":0,"collapsed":true}
{"type":"cell","id":"a0daa3","pos":1,"input":"# Pandas is used for data manipulation\nimport pandas as pd\n\n# Read in data as pandas dataframe and display first 5 rows\nfeatures = pd.read_csv('temps.csv')\nfeatures.head(5)","output":{"0":{"data":{"text/html":"<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>week</th>\n      <th>temp_2</th>\n      <th>temp_1</th>\n      <th>average</th>\n      <th>actual</th>\n      <th>friend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Fri</td>\n      <td>45</td>\n      <td>45</td>\n      <td>45.6</td>\n      <td>45</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Sat</td>\n      <td>44</td>\n      <td>45</td>\n      <td>45.7</td>\n      <td>44</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Sun</td>\n      <td>45</td>\n      <td>44</td>\n      <td>45.8</td>\n      <td>41</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>4</td>\n      <td>Mon</td>\n      <td>44</td>\n      <td>41</td>\n      <td>45.9</td>\n      <td>40</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Tues</td>\n      <td>41</td>\n      <td>40</td>\n      <td>46.0</td>\n      <td>44</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"output_type":"execute_result","exec_count":1}},"cell_type":"code","exec_count":1,"metadata":{"hideCode":false,"hidePrompt":false}}
{"type":"cell","id":"a1fa24","pos":36,"input":"import datetime\n\n# Dates of training values\nmonths = features[:, feature_list.index('month')]\ndays = features[:, feature_list.index('day')]\nyears = features[:, feature_list.index('year')]\n\n# List and then convert to datetime object\ndates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\ndates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n\n# Dataframe with true values and dates\ntrue_data = pd.DataFrame(data = {'date': dates, 'actual': labels})\n\n# Dates of predictions\nmonths = test_features[:, feature_list.index('month')]\ndays = test_features[:, feature_list.index('day')]\nyears = test_features[:, feature_list.index('year')]\n\n# Column of dates\ntest_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n\n# Convert to datetime objects\ntest_dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in test_dates]\n\n# Dataframe with predictions and dates\npredictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': predictions}) ","cell_type":"code","exec_count":19}
{"type":"cell","id":"a458e6","pos":30,"input":"## Variable Importances","cell_type":"markdown"}
{"type":"cell","id":"b67959","pos":16,"input":"We can create models with different hyperparameters to try and boost performance. The only way to find the best ones\nare to try a few and evaluate them! ","cell_type":"markdown"}
{"type":"cell","id":"b92ba0","pos":33,"input":"# New random forest with only the two most important variables\nrf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42)\n\n# Extract the two most important features\nimportant_indices = [feature_list.index('temp_1'), feature_list.index('average')]\ntrain_important = train_features[:, important_indices]\ntest_important = test_features[:, important_indices]\n\n# Train the random forest\nrf_most_important.fit(train_important, train_labels)\n\n# Make predictions and determine the error\npredictions = rf_most_important.predict(test_important)\n\nerrors = abs(predictions - test_labels)\n\n# Display the performance metrics\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n\nmape = np.mean(100 * (errors / test_labels))\naccuracy = 100 - mape\n\nprint('Accuracy:', round(accuracy, 2), '%.')","output":{"0":{"name":"stdout","output_type":"stream","text":"Mean Absolute Error: 3.9 degrees.\nAccuracy: 93.8 %.\n"}},"cell_type":"code","exec_count":17}
{"type":"cell","id":"bcb3ed","pos":10,"input":"# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25,\n                                                                           random_state = 42)","cell_type":"code","exec_count":6}
{"type":"cell","id":"c4151f","pos":35,"input":"# Import matplotlib for plotting and use magic command for Jupyter Notebooks\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Set the style\nplt.style.use('fivethirtyeight')\n\n# list of x locations for plotting\nx_values = list(range(len(importances)))\n\n# Make a bar chart\nplt.bar(x_values, importances, orientation = 'vertical')\n\n# Tick labels for x axis\nplt.xticks(x_values, feature_list, rotation='vertical')\n\n# Axis labels and title\nplt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances'); ","output":{"0":{"data":{"image/png":"dcef627f40863d4eb5c8d227e5b9a680b103f8db"},"output_type":"execute_result","exec_count":18}},"cell_type":"code","exec_count":18}
{"type":"cell","id":"c46c76","pos":11,"input":"print('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)","output":{"0":{"name":"stdout","output_type":"stream","text":"Training Features Shape: (261, 14)\nTraining Labels Shape: (261,)\nTesting Features Shape: (87, 14)\nTesting Labels Shape: (87,)\n"}},"cell_type":"code","exec_count":7}
{"type":"cell","id":"ca2f2f","pos":14,"input":"## Training the Forest","cell_type":"markdown"}
{"type":"cell","id":"caad87","pos":3,"input":"## One-Hot Encoding","cell_type":"markdown"}
{"type":"cell","id":"d23a62","pos":38,"input":"# Make the data accessible for plotting\ntrue_data['temp_1'] = features[:, feature_list.index('temp_1')]\ntrue_data['average'] = features[:, feature_list.index('average')]\ntrue_data['friend'] = features[:, feature_list.index('friend')]\n\n# Plot all the data as lines\nplt.plot(true_data['date'], true_data['actual'], 'b-', label  = 'actual', alpha = 1.0)\nplt.plot(true_data['date'], true_data['temp_1'], 'y-', label  = 'temp_1', alpha = 1.0)\nplt.plot(true_data['date'], true_data['average'], 'k-', label = 'average', alpha = 0.8)\nplt.plot(true_data['date'], true_data['friend'], 'r-', label = 'friend', alpha = 0.3)\n\n# Formatting plot\nplt.legend(); plt.xticks(rotation = '60');\n\n# Lables and title\nplt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual Max Temp and Variables');","output":{"0":{"data":{"image/png":"484e9489e9e75a7edc72cde6a5cc5e1fdb3f05f6"},"output_type":"execute_result","exec_count":26}},"cell_type":"code","exec_count":26}
{"type":"cell","id":"d383ea","pos":9,"input":"## Training and Testing Sets","cell_type":"markdown"}
{"type":"cell","id":"ea4dfe","pos":7,"input":"## Features and Labels","cell_type":"markdown"}
{"type":"cell","id":"ef7879","pos":25,"input":"Smaller tree for visualization.","cell_type":"markdown"}
{"type":"cell","id":"f5ce4f","pos":22,"input":"# Import tools needed for visualization\nfrom sklearn.tree import export_graphviz\nimport pydot\n\n# Pull out one tree from the forest\ntree = rf.estimators_[5]\n\n# Export the image to a dot file\nexport_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n\n# Use dot file to create a graph\n(graph, ) = pydot.graph_from_dot_file('tree.dot')\n\n# Write graph to a png file\ngraph.write_png('tree.png'); ","cell_type":"code","exec_count":13,"collapsed":true}
{"type":"cell","id":"f84381","pos":29,"input":"![Annotated Decision Tree](small_tree_annotated.PNG)","cell_type":"markdown"}
{"type":"cell","id":"f85d8e","pos":17,"input":"rf_new = RandomForestRegressor(n_estimators = 100, criterion = 'mse', max_depth = None, \n                               min_samples_split = 2, min_samples_leaf = 1)","cell_type":"code","exec_count":10,"collapsed":true}
{"type":"cell","id":"ff0d50","pos":37,"input":"# Plot the actual values\nplt.plot(true_data['date'], true_data['actual'], 'b-', label = 'actual')\n\n# Plot the predicted values\nplt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\nplt.xticks(rotation = '60'); \nplt.legend()\n\n# Graph labels\nplt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual and Predicted Values');\n","output":{"0":{"data":{"image/png":"a4b9532aab03d82fe125cdaca262b4b1a9f5ba4e"},"output_type":"execute_result","exec_count":20}},"cell_type":"code","exec_count":20}
{"type":"cell","id":"ff1994","pos":26,"input":"# Limit depth of tree to 2 levels\nrf_small = RandomForestRegressor(n_estimators=10, max_depth = 3, random_state=42)\nrf_small.fit(train_features, train_labels)\n\n# Extract the small tree\ntree_small = rf_small.estimators_[5]\n\n# Save the tree as a png image\nexport_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n\n(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n\ngraph.write_png('small_tree.png')","output":{"0":{"data":{"text/plain":"True"},"output_type":"execute_result","exec_count":15}},"cell_type":"code","exec_count":15}
{"type":"file","last_load":1526894156747}
{"type":"settings","kernel":"python3","backend_state":"running","metadata":{"hide_code_all_hidden":false,"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"trust":false,"kernel_state":"idle","kernel_usage":{"cpu":0,"memory":77291520}}