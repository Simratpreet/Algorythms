{"exec_count":115,"start":1526830983222,"input":"x = importances.index.values\ny = x[:30].tolist()","state":"done","pos":8.90625,"type":"cell","end":1526830983231,"id":"e6f1ee","kernel":"python2-ubuntu"}
{"exec_count":14,"start":1526840211051,"input":"# Load Train and Test Data\nimport pandas as pd\nimport numpy as np\n\ntrain_df = pd.read_csv(\"train-patient.csv\")\n\ntest_df = pd.read_csv(\"test-patient.csv\")","state":"done","pos":0,"cell_type":"code","type":"cell","end":1526840211334,"id":"6e1401","kernel":"python2-ubuntu"}
{"exec_count":15,"start":1526840212831,"input":"train_df.replace('NA', 0, inplace=True)\ntest_df.replace('NA', 0, inplace=True)","state":"done","pos":0.25,"type":"cell","end":1526840213314,"id":"ec132d","kernel":"python2-ubuntu"}
{"exec_count":16,"start":1526840213317,"input":"# Separate features and label\ntrain_label = train_df['PID_State']\ntrain_features = train_df.drop(['PID_State', 'PID'], axis=1)\n\ntest_features = test_df.drop(['PID_State', 'PID'], axis=1)","state":"done","pos":1,"cell_type":"code","type":"cell","end":1526840213336,"id":"475127","kernel":"python2-ubuntu"}
{"exec_count":18,"start":1526840213421,"input":"# Fill empty values with zero\ntrain_features.fillna(0, inplace=True)\ntest_features.fillna(0, inplace=True)","state":"done","pos":3,"cell_type":"code","type":"cell","end":1526840213435,"id":"7d15fb","kernel":"python2-ubuntu"}
{"exec_count":19,"start":1526840213439,"input":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\ntrain_features = scaler.fit_transform(train_features)\ntest_features = scaler.fit_transform(test_features)","state":"done","pos":4.5,"type":"cell","end":1526840213532,"id":"a24d3b","kernel":"python2-ubuntu"}
{"exec_count":20,"start":1526840213535,"input":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train_features, train_label, test_size=0.20)","state":"done","pos":6,"cell_type":"code","type":"cell","end":1526840213605,"id":"5c5077","kernel":"python2-ubuntu"}
{"exec_count":22,"start":1526840213646,"input":"# from sklearn.decomposition import PCA\n\n# pca = PCA(.95)\n# pca.fit(X_train)\n# X_train = pca.transform(X_train)\n# X_test = pca.transform(X_test)\n\n# test_features = pca.transform(test_features)","state":"done","pos":6.5,"type":"cell","end":1526840213711,"id":"4a6593","kernel":"python2-ubuntu"}
{"exec_count":23,"start":1526840213714,"input":"# Try Random Forest\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n\nclf = RandomForestClassifier(criterion='entropy')\n#clf = KNeighborsClassifier()\n#clf = XGBClassifier()\n#clf = SVC()\n#clf = DecisionTreeClassifier(max_depth=2)\n#clf = GradientBoostingClassifier()\n\nclf.fit(X_train[:3000], y_train[:3000])\n\ny_pred = clf.predict(X_test)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\nsig_clf.fit(X_train[3000:4000], y_train[3000:4000])\n\ny_pred = sig_clf.predict(X_test)","state":"done","pos":7,"cell_type":"code","type":"cell","end":1526840214039,"id":"95b39a","kernel":"python2-ubuntu"}
{"exec_count":27,"start":1526834945174,"input":"np.savetxt(\"output.csv\", predictions_conv, delimiter=\",\", fmt='%s')","state":"done","pos":10,"cell_type":"code","type":"cell","end":1526834945209,"id":"928f61","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"(4000, 79)"},"exec_count":21}},"exec_count":21,"start":1526840213631,"input":"X_train.shape","state":"done","pos":6.25,"type":"cell","end":1526840213637,"id":"22c8d5","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"0.857"},"exec_count":24}},"exec_count":24,"start":1526840214042,"input":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_pred)","state":"done","pos":8.5,"type":"cell","end":1526840214108,"id":"1c87d5","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"array(['D0', 'D0', 'P', ..., 'D0', 'D0', 'D0'], dtype=object)"},"exec_count":26}},"exec_count":26,"start":1526834942070,"input":"converter = lambda x: str('P') if x==0 else (str('D0') if x == 1 else str('DS'))\nvfunc = np.vectorize(converter, otypes=[object])\npredictions_conv = vfunc(predictions) \npredictions_conv","state":"done","pos":9.5,"type":"cell","end":1526834942093,"id":"a020f0","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"array(['var8', 'var9', 'var29', 'var10', 'var42', 'var35', 'var6',\n       'var13', 'var11', 'var31', 'var5', 'var46', 'var37', 'var38',\n       'var45', 'var47', 'var33', 'var40', 'var44', 'var39', 'var48',\n       'var43', 'var50', 'var4', 'var16', 'var32', 'var23', 'var30',\n       'var22', 'var21', 'var78', 'var57', 'var26', 'var77', 'var2',\n       'var20', 'var58', 'var34', 'var59', 'var62', 'var53', 'var60',\n       'var52', 'var61', 'var79', 'var28', 'var36', 'var41', 'var54',\n       'var75', 'var12', 'var56', 'var55', 'var63', 'var27', 'var24',\n       'var65', 'var7', 'var76', 'var74', 'var69', 'var68', 'var25',\n       'var67', 'var64', 'var51', 'var18', 'var19', 'var1', 'var66',\n       'var14', 'var15', 'var70', 'var71', 'var72', 'var73', 'var17',\n       'var49', 'var3'], dtype=object)"},"exec_count":104}},"exec_count":104,"start":1526830792801,"input":"importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(best_clf.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.index.values","state":"done","pos":8.875,"type":"cell","end":1526830792841,"id":"0497e7","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"array([0, 1, 2])"},"exec_count":17}},"exec_count":17,"start":1526840213343,"input":"# Encode label categories\ntrain_label = train_label.apply(lambda x: 0 if x=='P' else (1 if x == 'DO' else 2))\ntrain_label.unique()","state":"done","pos":2,"cell_type":"code","type":"cell","end":1526840213418,"id":"b65d8a","kernel":"python2-ubuntu"}
{"output":{"0":{"ename":"ValueError","evalue":"Number of features of the model must match the input. Model n_features is 38 and input n_features is 79 ","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-39-1f64ab8acf0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    382\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 38 and input n_features is 79 "]}},"exec_count":39,"start":1526835434070,"input":"predictions = best_clf.predict(test_features)","state":"done","pos":9,"cell_type":"code","type":"cell","end":1526835434135,"id":"1005dd","kernel":"python2-ubuntu"}
{"output":{"0":{"text":"Final Model trained on full data\n------\nAccuracy on testing data: 0.8850\n\nFinal Model trained on reduced data\n------\nAccuracy on testing data: 0.8820\n","name":"stdout"}},"exec_count":116,"start":1526830985123,"input":"# Import functionality for cloning a model\nfrom sklearn.base import clone\n\n# Reduce the feature space\nX_train_reduced = X_train[y]\nX_test_reduced = X_test[y]\n\n# Train on the \"best\" model found from grid search earlier\nclf = (clone(best_clf)).fit(X_train_reduced, y_train)\n\n# Make new predictions\nreduced_predictions = clf.predict(X_test_reduced)\n\n# Report scores from the final model using both versions of data\nprint(\"Final Model trained on full data\\n------\")\nprint(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint(\"\\nFinal Model trained on reduced data\\n------\")\nprint(\"Accuracy on testing data: {:.4f}\".format(accuracy_score(y_test, reduced_predictions)))","state":"done","pos":8.9375,"type":"cell","end":1526830986294,"id":"160610","kernel":"python2-ubuntu"}
{"output":{"0":{"text":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=25, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n","name":"stdout"},"1":{"text":"Unoptimized model\n------\nAccuracy score on testing data: 0.8470\n\nOptimized Model\n------\nFinal accuracy score on the testing data: 0.8680\n","name":"stdout"}},"exec_count":38,"start":1526835301373,"input":"# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\n\n# TODO: Initialize the classifier\nclf = RandomForestClassifier(criterion='entropy')\n#clf = GradientBoostingClassifier()\n\n# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\nparameters = {'n_estimators': [10, 50, 75, 100], 'max_depth': [2, 25, 50, 75, 100]}\n\n# TODO: Make an fbeta_score scoring object using make_scorer()\nscorer = make_scorer(accuracy_score)\n\n# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\ngrid_obj = GridSearchCV(clf, parameters, scorer)\n\n# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train, y_train)\n\n# Get the estimator\nbest_clf = grid_fit.best_estimator_\nprint best_clf\n# Make predictions using the unoptimized and model\npredictions = (clf.fit(X_train, y_train)).predict(X_test)\nbest_predictions = best_clf.predict(X_test)\n\n# Report the before-and-afterscores\nprint(\"Unoptimized model\\n------\")\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint(\"\\nOptimized Model\\n------\")\nprint(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))","state":"done","pos":8.75,"type":"cell","end":1526835413544,"id":"8c42c6","kernel":"python2-ubuntu"}
{"type":"cell","id":"cac194","pos":8,"input":"**Random Forest has given results**","cell_type":"markdown"}
{"type":"file","last_load":1526827498357}
{"type":"settings","kernel":"python2-ubuntu","backend_state":"running","metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.12"}},"trust":true,"kernel_usage":{"cpu":0,"memory":5328896},"kernel_state":"idle"}