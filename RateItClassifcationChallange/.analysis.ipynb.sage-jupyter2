{"exec_count":35,"start":1526973038270,"input":"# Check if these 10 features work good on any other model\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclf = GradientBoostingClassifier()\nclf.fit(X_train_reduced, y_train)\n\ny_pred = clf.predict(X_test_reduced)","state":"done","pos":7.875,"type":"cell","end":1526973040905,"id":"d8f071","kernel":"python2-ubuntu"}
{"exec_count":40,"input":"n_features = 5\ntop_n_features = importances.index.values[:n_features].tolist()","state":"done","pos":5.328125,"type":"cell","id":"48c408","kernel":"python2-ubuntu"}
{"exec_count":75,"start":1526975881568,"input":"# Load Train and Test Data\nimport pandas as pd\nimport numpy as np\n\ntrain_df = pd.read_csv(\"train-rateit.csv\")\n\ntest_df = pd.read_csv(\"test-rateit.csv\")","state":"done","pos":0,"type":"cell","end":1526975882120,"id":"3ccea0","kernel":"python2-ubuntu"}
{"exec_count":76,"start":1526975883373,"input":"# Separate features and label\ntrain_label = train_df['target_bin']\ntrain_features = train_df.drop(['target_bin', 'content_id'], axis=1)\n\ntest_features = test_df.drop(['content_id'], axis=1)","state":"done","pos":1,"type":"cell","end":1526975883394,"id":"a17fae","kernel":"python2-ubuntu"}
{"exec_count":78,"start":1526975883423,"input":"# Fill empty values with zero\ntrain_features.fillna(0, inplace=True)\ntest_features.fillna(0, inplace=True)","state":"done","pos":1.75,"type":"cell","end":1526975883477,"id":"e05709","kernel":"python2-ubuntu"}
{"exec_count":79,"start":1526975883480,"input":"# Fill na in day of week where day of week is 0\ntrain_features['day_of_week'] = train_features['day_of_week'].apply(lambda x: \"NA\" if x==0 else x)\ntest_features['day_of_week'] = test_features['day_of_week'].apply(lambda x: \"NA\" if x==0 else x)","state":"done","pos":1.875,"type":"cell","end":1526975883535,"id":"a4a2c2","kernel":"python2-ubuntu"}
{"exec_count":80,"start":1526975883538,"input":"# One-Hot Encode day of week\ntrain_features = pd.get_dummies(train_features)\ntest_features = pd.get_dummies(test_features)","state":"done","pos":2.875,"type":"cell","end":1526975883595,"id":"bc4109","kernel":"python2-ubuntu"}
{"exec_count":81,"start":1526975883601,"input":"# %matplotlib inline\n\n# import matplotlib.pyplot as plt\n# plt.rcParams['figure.figsize'] = [50, 50]\n\n# #fig = plt.figure(figsize = (11,5))\n# train_features.hist()\n# plt.show()","state":"done","pos":3.375,"type":"cell","end":1526975883608,"id":"204df5","kernel":"python2-ubuntu"}
{"exec_count":82,"start":1526975883612,"input":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train_features, train_label, test_size=0.20)","state":"done","pos":3.875,"type":"cell","end":1526975883645,"id":"bda974","kernel":"python2-ubuntu"}
{"exec_count":83,"start":1526975883652,"input":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 4)\npca.fit(X_train)\n\nX_train = pca.transform(X_train)\nX_test = pca.transform(X_test)","state":"done","pos":4.375,"type":"cell","end":1526975884669,"id":"328144","kernel":"python2-ubuntu"}
{"exec_count":84,"start":1526975887677,"input":"# Try Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)","state":"done","pos":4.875,"type":"cell","end":1526975888855,"id":"ab704c","kernel":"python2-ubuntu"}
{"exec_count":89,"start":1526976143783,"input":"#predictions = clf.predict(test_features[top_n_features])\ntest_features = pca.transform(test_features)\npredictions = best_clf.predict(test_features)","state":"done","pos":5.375,"type":"cell","end":1526976144193,"id":"9c33f6","kernel":"python2-ubuntu"}
{"exec_count":90,"start":1526976148435,"input":"np.savetxt(\"output.csv\", np.asarray(predictions), delimiter=\",\")","state":"done","pos":5.875,"type":"cell","end":1526976148559,"id":"cdf1c2","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"0.5021494491006686"},"exec_count":36}},"exec_count":36,"start":1526973044466,"input":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test, y_pred)","state":"done","pos":8.875,"type":"cell","end":1526973044483,"id":"996364","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"0.690775018167828"},"exec_count":85}},"exec_count":85,"start":1526975891833,"input":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test, y_pred)","state":"done","pos":5.1875,"type":"cell","end":1526975891854,"id":"e22ab1","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"Index([u'avg_word_length', u'day_of_week', u'feat1', u'feat2', u'feat3',\n       u'feat4', u'feat5', u'feat6', u'feat7', u'feat8', u'feat9', u'feat10',\n       u'feat11', u'feat12', u'feat13', u'feat14', u'feat15', u'feat16',\n       u'feat17', u'feat18', u'feat19', u'feat20', u'feat21', u'feat22',\n       u'feat23', u'feat24', u'feat25', u'feat26', u'feat27', u'feat28',\n       u'feat29', u'feat30', u'images', u'meta_length', u'negativity',\n       u'negativity2', u'negativity3', u'negativity4', u'negativity5',\n       u'num_content_words', u'num_links', u'num_links_2', u'num_title_words',\n       u'num_uniq_content_words', u'positivity', u'positivity2',\n       u'positivity3', u'positivity4', u'positivity5', u'ratio_non_stop_words',\n       u'ratio_uniq_non_stop_words', u'sentiment', u'sentiment2', u'topic_1',\n       u'topic_2', u'topic_3', u'topic_4', u'topic_5', u'topic_6',\n       u'tracked_for_days', u'videos'],\n      dtype='object')"},"exec_count":77}},"exec_count":77,"start":1526975883409,"input":"train_features.columns","state":"done","pos":1.5,"type":"cell","end":1526975883418,"id":"3f4923","kernel":"python2-ubuntu"}
{"output":{"0":{"data":{"text/plain":"array(['feat9', 'feat8', 'feat23', 'feat16', 'feat18', 'feat17',\n       'tracked_for_days', 'feat6', 'feat12', 'feat14',\n       'num_content_words', 'num_uniq_content_words',\n       'ratio_uniq_non_stop_words', 'feat15', 'avg_word_length', 'feat13',\n       'feat3', 'feat22', 'feat2', 'feat10', 'sentiment', 'positivity3',\n       'feat11', 'positivity', 'feat7', 'negativity3', 'num_links',\n       'feat28', 'feat29', 'positivity2', 'negativity', 'feat27',\n       'negativity2', 'num_title_words', 'images', 'feat24', 'feat30',\n       'feat4', 'sentiment2', 'feat25', 'feat26', 'negativity5',\n       'num_links_2', 'negativity4', 'feat19', 'feat21', 'feat20',\n       'positivity4', 'meta_length', 'positivity5', 'videos', 'feat5',\n       'topic_5', 'feat1', 'day_of_week_sunday', 'day_of_week_thursday',\n       'day_of_week_tuesday', 'day_of_week_wednesday', 'topic_1',\n       'topic_2', 'topic_3', 'topic_4', 'topic_6', 'day_of_week_friday',\n       'day_of_week_monday', 'day_of_week_saturday',\n       'ratio_non_stop_words', 'day_of_week_NA'], dtype=object)"},"exec_count":32}},"exec_count":32,"start":1526973016470,"input":"# Get Feature importances\nimportances = pd.DataFrame({'feature': X_train.columns, 'importance':np.round(best_clf.feature_importances_, 3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.index.values","state":"done","pos":5.3125,"type":"cell","end":1526973016495,"id":"450019","kernel":"python2-ubuntu"}
{"output":{"0":{"text":"Final Model trained on full data\n------\nROC AUC score on testing data: 0.6732\n\nFinal Model trained on reduced data\n------\nROC AUC score on testing data: 0.6976\n","name":"stdout"}},"exec_count":42,"start":1526973214484,"input":"# Import functionality for cloning a model\nfrom sklearn.base import clone\n\n# Reduce the feature space\nX_train_reduced = X_train[top_n_features]\nX_test_reduced = X_test[top_n_features]\n\n# Train on the \"best\" model found from grid search earlier\nclf = (clone(best_clf)).fit(X_train_reduced, y_train)\n\n# Make new predictions\nreduced_predictions = clf.predict(X_test_reduced)\n\n# Report scores from the final model using both versions of data\nprint(\"Final Model trained on full data\\n------\")\nprint(\"ROC AUC score on testing data: {:.4f}\".format(roc_auc_score(y_test, predictions)))\nprint(\"\\nFinal Model trained on reduced data\\n------\")\nprint(\"ROC AUC score on testing data: {:.4f}\".format(roc_auc_score(y_test, reduced_predictions)))","state":"done","pos":5.34375,"type":"cell","end":1526973224412,"id":"2f0ce1","kernel":"python2-ubuntu"}
{"output":{"0":{"text":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=100, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n","name":"stdout"},"1":{"text":"Unoptimized model\n------\nROC AUC score on testing data: 0.6858\n\nOptimized Model\n------\nFinal ROC AUC score on the testing data: 0.7171\n","name":"stdout"}},"exec_count":86,"start":1526975900023,"input":"# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\n\n# TODO: Initialize the classifier\nclf = RandomForestClassifier()\n\n# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\nparameters = {'n_estimators': [10, 50, 75, 100], 'max_depth': [2, 25, 50, 75, 100]}\n\n# TODO: Make an fbeta_score scoring object using make_scorer()\nscorer = make_scorer(roc_auc_score)\n\n# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\ngrid_obj = GridSearchCV(clf, parameters, scorer)\n\n# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train, y_train)\n\n# Get the estimator\nbest_clf = grid_fit.best_estimator_\nprint best_clf\n# Make predictions using the unoptimized and model\npredictions = (clf.fit(X_train, y_train)).predict(X_test)\nbest_predictions = best_clf.predict(X_test)\n\n# Report the before-and-afterscores\nprint(\"Unoptimized model\\n------\")\nprint(\"ROC AUC score on testing data: {:.4f}\".format(roc_auc_score(y_test, predictions)))\nprint(\"\\nOptimized Model\\n------\")\nprint(\"Final ROC AUC score on the testing data: {:.4f}\".format(roc_auc_score(y_test, best_predictions)))","state":"done","pos":5.25,"type":"cell","end":1526976064282,"id":"b5bc1d","kernel":"python2-ubuntu"}
{"type":"cell","id":"42f025","pos":5.125,"input":"**Random Forest has given results**","cell_type":"markdown"}
{"type":"cell","id":"a8da5c","pos":6.875,"input":""}
{"type":"file","last_load":1526821915512}
{"type":"settings","backend_state":"running","trust":true,"kernel":"python2-ubuntu","kernel_usage":{"cpu":0,"memory":5300224},"kernel_state":"idle"}